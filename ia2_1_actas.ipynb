{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMKdkmWeaWCq0PpfIwsjbn5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pereira-71/-EXAMEN-01-PRIMER-PARCIAL/blob/main/ia2_1_actas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Instalar dependencias\n",
        "!pip install pytesseract pillow opencv-python scikit-learn seaborn pandas torch torchvision\n",
        "!apt-get update\n",
        "!apt-get install -y tesseract-ocr tesseract-ocr-spa\n",
        "\n",
        "# 2. Copiar todo el código del artifact y ejecutar\n",
        "\n",
        "# 3. Para demo completo (recomendado)\n",
        "#main_demo()\n",
        "\n",
        "# 4. Para procesar una sola acta específica\n",
        "#test_single_acta()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zl8JNOhnzkJe",
        "outputId": "fadea945-62e7-4384-fc3e-0a89f82d8bcf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from pytesseract) (25.0)\n",
            "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.12/dist-packages (from opencv-python) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.12/dist-packages (from seaborn) (3.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://cli.github.com/packages stable InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,617 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,576 kB]\n",
            "Fetched 5,577 kB in 3s (1,884 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "tesseract-ocr-spa is already the newest version (1:4.00~git30-7274cfa-1.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import sqlite3\n",
        "import json\n",
        "import pickle\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "import seaborn as sns\n",
        "from PIL import Image, ImageDraw\n",
        "import pytesseract\n",
        "import re\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ================================\n",
        "# 1. CONFIGURACIÓN INICIAL\n",
        "# ================================\n",
        "\n",
        "class ConfiguracionSistema:\n",
        "    def __init__(self):\n",
        "        # Rutas principales\n",
        "        self.ruta_base = '/content/drive/MyDrive/actas_electorales_2025_processed'\n",
        "        self.ruta_modelos = '/content/drive/MyDrive/modelos_actas'\n",
        "        self.ruta_bd = '/content/drive/MyDrive/electoral_database.db'\n",
        "\n",
        "        # Configuración de recintos\n",
        "        self.recintos_config = {\n",
        "            'Campo_Deportivo_20_de_Octubre': {'prefijo': 'acta_CDP_', 'total': 7},\n",
        "            'Campo_Deportivo_Barrio_Lindo': {'prefijo': 'acta_CDBL_', 'total': 4},\n",
        "            'Campo_Deportivo_Noria_Alta': {'prefijo': 'acta_CDNA_', 'total': 7},\n",
        "            'Campo_Deportivo_San_Juanillo_Bajo': {'prefijo': 'acta_CDSJ_', 'total': 9},\n",
        "            'Campo_Deportivo_Zona_America': {'prefijo': 'acta_CDSA_', 'total': 8},\n",
        "            'Campo_Deportivo_Zona_San_Francisco': {'prefijo': 'acta_CDZSF_', 'total': 7},\n",
        "            'Centro_Recreacional_La_Esperanza': {'prefijo': 'acta_ZRLE_', 'total': 4},\n",
        "            'Colegio_Bernardo_Monteagudo': {'prefijo': 'acta_CBM_', 'total': 6}\n",
        "        }\n",
        "\n",
        "        # Partidos políticos\n",
        "        self.partidos = ['AP', 'LYP_ADN', 'APB_SUMATE', 'LIBRE', 'FP', 'MAS_IPSP', 'MORENA', 'UNIDAD', 'PDC']\n",
        "\n",
        "        # Configuración del modelo\n",
        "        self.imagen_size = (224, 224)\n",
        "        self.batch_size = 8  # Reducido para Colab gratuito\n",
        "        self.learning_rate = 0.001\n",
        "        self.epochs_per_session = 5  # Entrenar en sesiones cortas\n",
        "\n",
        "# ================================\n",
        "# 4. MODELO DE DEEP LEARNING\n",
        "# ================================\n",
        "\n",
        "class ModeloClasificadorActas(nn.Module):\n",
        "    def __init__(self, num_classes=10):  # Ajustar según número de mesas\n",
        "        super(ModeloClasificadorActas, self).__init__()\n",
        "\n",
        "        # Usar MNASNet1_0 como base (ligero para Colab gratuito)\n",
        "        self.backbone = torch.hub.load('pytorch/vision:v0.10.0', 'mnasnet1_0', pretrained=True)\n",
        "\n",
        "        # Congelar las primeras capas para transfer learning eficiente\n",
        "        for param in list(self.backbone.parameters())[:-10]:\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Modificar la última capa\n",
        "        self.backbone.classifier = nn.Sequential(\n",
        "            nn.Linear(1280, 256),  # MNASNet1_0 tiene 1280 características\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),  # Aumentado para prevenir overfitting\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),  # Aumentado para prevenir overfitting\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.backbone(x)\n",
        "\n",
        "class DatasetActas(Dataset):\n",
        "    def __init__(self, imagenes_paths, etiquetas, transform=None):\n",
        "        self.imagenes_paths = imagenes_paths\n",
        "        self.etiquetas = etiquetas\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imagenes_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        imagen = Image.open(self.imagenes_paths[idx]).convert('RGB')\n",
        "        etiqueta = self.etiquetas[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            imagen = self.transform(imagen)\n",
        "\n",
        "        return imagen, etiqueta\n",
        "\n",
        "# ================================\n",
        "# 5. ENTRENADOR DEL MODELO\n",
        "# ================================\n",
        "\n",
        "class EntrenadorModelo:\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        print(f\"Usando dispositivo: {self.device}\")\n",
        "\n",
        "        # Crear directorio para modelos\n",
        "        os.makedirs(self.config.ruta_modelos, exist_ok=True)\n",
        "\n",
        "    def preparar_datos(self):\n",
        "        \"\"\"Prepara los datos de entrenamiento, validación y prueba\"\"\"\n",
        "        imagenes_paths = []\n",
        "        etiquetas = []\n",
        "\n",
        "        # Recopilar todas las imágenes\n",
        "        for recinto, info in self.config.recintos_config.items():\n",
        "            ruta_recinto = os.path.join(self.config.ruta_base, recinto)\n",
        "            if os.path.exists(ruta_recinto):\n",
        "                for i in range(1, info['total'] + 1):\n",
        "                    nombre_archivo = f\"{info['prefijo']}{i}.jpeg\"\n",
        "                    ruta_imagen = os.path.join(ruta_recinto, nombre_archivo)\n",
        "                    if os.path.exists(ruta_imagen):\n",
        "                        imagenes_paths.append(ruta_imagen)\n",
        "                        etiquetas.append(i - 1)  # Ajustar etiquetas para que comiencen en 0\n",
        "\n",
        "        # Dividir datos: 70% entrenamiento, 10% validación, 20% prueba\n",
        "        train_val_paths, test_paths, train_val_labels, test_labels = train_test_split(\n",
        "            imagenes_paths, etiquetas, test_size=0.2, random_state=42, stratify=etiquetas\n",
        "        )\n",
        "        train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
        "            train_val_paths, train_val_labels, test_size=0.125, random_state=42, stratify=train_val_labels\n",
        "        )  # 0.125 de 80% = 10% del total\n",
        "\n",
        "        # Transformaciones de datos\n",
        "        transform_train = transforms.Compose([\n",
        "            transforms.Resize(self.config.imagen_size),\n",
        "            transforms.RandomHorizontalFlip(p=0.3),  # Aumentado para más variedad\n",
        "            transforms.RandomRotation(degrees=5),  # Más rotación\n",
        "            transforms.ColorJitter(brightness=0.2, contrast=0.2),  # Más variación\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        transform_val_test = transforms.Compose([\n",
        "            transforms.Resize(self.config.imagen_size),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        # Crear datasets\n",
        "        train_dataset = DatasetActas(train_paths, train_labels, transform_train)\n",
        "        val_dataset = DatasetActas(val_paths, val_labels, transform_val_test)\n",
        "        test_dataset = DatasetActas(test_paths, test_labels, transform_val_test)\n",
        "\n",
        "        # Crear dataloaders\n",
        "        train_loader = DataLoader(train_dataset, batch_size=self.config.batch_size,\n",
        "                                 shuffle=True, num_workers=2)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=self.config.batch_size,\n",
        "                                shuffle=False, num_workers=2)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=self.config.batch_size,\n",
        "                                shuffle=False, num_workers=2)\n",
        "\n",
        "        return train_loader, val_loader, test_loader, len(train_dataset), len(val_dataset), len(test_dataset)\n",
        "\n",
        "    def entrenar_sesion(self, sesion_num):\n",
        "        \"\"\"Entrena el modelo por una sesión limitada con early stopping\"\"\"\n",
        "        print(f\"\\n=== INICIANDO SESIÓN DE ENTRENAMIENTO {sesion_num} ===\")\n",
        "\n",
        "        # Preparar datos\n",
        "        train_loader, val_loader, test_loader, train_size, val_size, test_size = self.preparar_datos()\n",
        "        print(f\"Datos: {train_size} entrenamiento, {val_size} validación, {test_size} prueba\")\n",
        "\n",
        "        # Crear o cargar modelo\n",
        "        num_classes = len(set().union(*[list(range(1, info['total']+1))\n",
        "                                       for info in self.config.recintos_config.values()]))\n",
        "\n",
        "        modelo = ModeloClasificadorActas(num_classes=num_classes).to(self.device)\n",
        "\n",
        "        # Cargar modelo previo si existe\n",
        "        ruta_modelo_anterior = os.path.join(self.config.ruta_modelos,\n",
        "                                          f'modelo_sesion_{sesion_num-1}.pth')\n",
        "        if sesion_num > 1 and os.path.exists(ruta_modelo_anterior):\n",
        "            print(f\"Cargando modelo de sesión anterior: {ruta_modelo_anterior}\")\n",
        "            modelo.load_state_dict(torch.load(ruta_modelo_anterior, map_location=self.device))\n",
        "\n",
        "        # Configurar optimizador y función de pérdida\n",
        "        criterio = nn.CrossEntropyLoss()\n",
        "        optimizador = optim.Adam(modelo.parameters(), lr=self.config.learning_rate, weight_decay=0.001)\n",
        "        scheduler = optim.lr_scheduler.StepLR(optimizador, step_size=3, gamma=0.7)\n",
        "\n",
        "        # Listas para tracking\n",
        "        train_losses = []\n",
        "        train_accuracies = []\n",
        "        val_losses = []\n",
        "        val_accuracies = []\n",
        "\n",
        "        # Early stopping\n",
        "        patience = 2\n",
        "        best_val_loss = float('inf')\n",
        "        best_model_state = None\n",
        "        counter = 0\n",
        "\n",
        "        # Entrenamiento\n",
        "        for epoca in range(self.config.epochs_per_session):\n",
        "            modelo.train()\n",
        "            running_loss = 0.0\n",
        "            correct = 0\n",
        "            total = 0\n",
        "\n",
        "            print(f\"\\nÉpoca {epoca + 1}/{self.config.epochs_per_session}\")\n",
        "\n",
        "            for batch_idx, (imagenes, etiquetas) in enumerate(train_loader):\n",
        "                imagenes, etiquetas = imagenes.to(self.device), etiquetas.to(self.device)\n",
        "\n",
        "                # Forward pass\n",
        "                optimizador.zero_grad()\n",
        "                outputs = modelo(imagenes)\n",
        "                loss = criterio(outputs, etiquetas)\n",
        "\n",
        "                # Backward pass\n",
        "                loss.backward()\n",
        "                optimizador.step()\n",
        "\n",
        "                # Estadísticas\n",
        "                running_loss += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += etiquetas.size(0)\n",
        "                correct += predicted.eq(etiquetas).sum().item()\n",
        "\n",
        "                if batch_idx % 5 == 0:\n",
        "                    print(f'Batch {batch_idx}/{len(train_loader)}, '\n",
        "                          f'Loss: {loss.item():.4f}, '\n",
        "                          f'Acc: {100.*correct/total:.2f}%')\n",
        "\n",
        "            # Estadísticas de época (entrenamiento)\n",
        "            epoch_loss = running_loss / len(train_loader)\n",
        "            epoch_acc = 100. * correct / total\n",
        "            train_losses.append(epoch_loss)\n",
        "            train_accuracies.append(epoch_acc)\n",
        "\n",
        "            # Evaluación en validación\n",
        "            modelo.eval()\n",
        "            val_loss = 0.0\n",
        "            correct_val = 0\n",
        "            total_val = 0\n",
        "            with torch.no_grad():\n",
        "                for imagenes, etiquetas in val_loader:\n",
        "                    imagenes, etiquetas = imagenes.to(self.device), etiquetas.to(self.device)\n",
        "                    outputs = modelo(imagenes)\n",
        "                    loss = criterio(outputs, etiquetas)\n",
        "                    val_loss += loss.item()\n",
        "                    _, predicted = outputs.max(1)\n",
        "                    total_val += etiquetas.size(0)\n",
        "                    correct_val += predicted.eq(etiquetas).sum().item()\n",
        "\n",
        "            epoch_val_loss = val_loss / len(val_loader)\n",
        "            epoch_val_acc = 100. * correct_val / total_val\n",
        "            val_losses.append(epoch_val_loss)\n",
        "            val_accuracies.append(epoch_val_acc)\n",
        "\n",
        "            print(f'Época {epoca + 1} - Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.2f}%')\n",
        "            print(f'              Val Loss: {epoch_val_loss:.4f}, Val Acc: {epoch_val_acc:.2f}%')\n",
        "\n",
        "            # Early stopping\n",
        "            if epoch_val_loss < best_val_loss:\n",
        "                best_val_loss = epoch_val_loss\n",
        "                best_model_state = modelo.state_dict()\n",
        "                counter = 0\n",
        "            else:\n",
        "                counter += 1\n",
        "                if counter >= patience:\n",
        "                    print(f\"Early stopping activado en época {epoca + 1}\")\n",
        "                    modelo.load_state_dict(best_model_state)\n",
        "                    break\n",
        "\n",
        "            scheduler.step()\n",
        "\n",
        "            # Guardar progreso en BD\n",
        "            bd = GestorBaseDatos(self.config.ruta_bd)\n",
        "            conn = sqlite3.connect(bd.ruta_bd)\n",
        "            cursor = conn.cursor()\n",
        "            cursor.execute('''\n",
        "                INSERT INTO historial_entrenamiento (sesion, epoca, accuracy, loss)\n",
        "                VALUES (?, ?, ?, ?)\n",
        "            ''', (sesion_num, epoca + 1, epoch_acc, epoch_loss))\n",
        "            conn.commit()\n",
        "            conn.close()\n",
        "\n",
        "        # Evaluación final en prueba\n",
        "        accuracy_prueba, reporte_clasificacion = self.evaluar_modelo(modelo, test_loader)\n",
        "\n",
        "        # Guardar modelo de la sesión\n",
        "        ruta_modelo_guardado = os.path.join(self.config.ruta_modelos,\n",
        "                                          f'modelo_sesion_{sesion_num}.pth')\n",
        "        torch.save(modelo.state_dict(), ruta_modelo_guardado)\n",
        "\n",
        "        print(f\"\\nModelo guardado en: {ruta_modelo_guardado}\")\n",
        "        print(f\"Accuracy en prueba: {accuracy_prueba:.2f}%\")\n",
        "\n",
        "        return {\n",
        "            'train_losses': train_losses,\n",
        "            'train_accuracies': train_accuracies,\n",
        "            'val_losses': val_losses,\n",
        "            'val_accuracies': val_accuracies,\n",
        "            'test_accuracy': accuracy_prueba,\n",
        "            'classification_report': reporte_clasificacion\n",
        "        }\n",
        "\n",
        "    def evaluar_modelo(self, modelo, test_loader):\n",
        "        \"\"\"Evalúa el modelo en el conjunto de prueba\"\"\"\n",
        "        modelo.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        all_predicted = []\n",
        "        all_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for imagenes, etiquetas in test_loader:\n",
        "                imagenes, etiquetas = imagenes.to(self.device), etiquetas.to(self.device)\n",
        "                outputs = modelo(imagenes)\n",
        "                _, predicted = outputs.max(1)\n",
        "\n",
        "                total += etiquetas.size(0)\n",
        "                correct += predicted.eq(etiquetas).sum().item()\n",
        "\n",
        "                all_predicted.extend(predicted.cpu().numpy())\n",
        "                all_labels.extend(etiquetas.cpu().numpy())\n",
        "\n",
        "        accuracy = 100. * correct / total\n",
        "        reporte = classification_report(all_labels, all_predicted)\n",
        "\n",
        "        return accuracy, reporte\n",
        "\n",
        "# ================================\n",
        "# 6. SISTEMA PRINCIPAL (Solo la parte modificada)\n",
        "# ================================\n",
        "\n",
        "class SistemaElectoral:\n",
        "    # ... (resto del código igual hasta visualizar_entrenamiento)\n",
        "\n",
        "    def visualizar_entrenamiento(self, sesion, resultado):\n",
        "        \"\"\"Visualiza los resultados del entrenamiento\"\"\"\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "        # Gráfico de pérdida\n",
        "        axes[0].plot(resultado['train_losses'], label='Train Loss', color='red')\n",
        "        axes[0].plot(resultado['val_losses'], label='Val Loss', color='orange')\n",
        "        axes[0].set_xlabel('Época')\n",
        "        axes[0].set_ylabel('Pérdida')\n",
        "        axes[0].set_title(f'Pérdida - Sesión {sesion}')\n",
        "        axes[0].legend()\n",
        "        axes[0].grid(True)\n",
        "\n",
        "        # Gráfico de accuracy\n",
        "        axes[1].plot(resultado['train_accuracies'], label='Train Accuracy', color='blue')\n",
        "        axes[1].plot(resultado['val_accuracies'], label='Val Accuracy', color='green')\n",
        "        axes[1].axhline(y=resultado['test_accuracy'], color='purple', linestyle='--',\n",
        "                       label=f'Test Accuracy: {resultado[\"test_accuracy\"]:.2f}%')\n",
        "        axes[1].set_xlabel('Época')\n",
        "        axes[1].set_ylabel('Accuracy (%)')\n",
        "        axes[1].set_title(f'Accuracy - Sesión {sesion}')\n",
        "        axes[1].legend()\n",
        "        axes[1].grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        print(f\"\\nReporte de Clasificación - Sesión {sesion}:\")\n",
        "        print(resultado['classification_report'])\n",
        "\n",
        "    # ... (resto del código igual: procesar_acta_demo, visualizar_procesamiento, etc.)"
      ],
      "metadata": {
        "id": "ljIwiPgs3Ym_"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}